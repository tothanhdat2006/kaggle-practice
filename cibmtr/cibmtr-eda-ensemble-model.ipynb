{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"},{"sourceId":211322530,"sourceType":"kernelVersion"}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:01.751155Z","iopub.execute_input":"2025-01-04T14:07:01.751622Z","iopub.status.idle":"2025-01-04T14:07:01.760855Z","shell.execute_reply.started":"2025-01-04T14:07:01.751587Z","shell.execute_reply":"2025-01-04T14:07:01.759970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_dict = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/data_dictionary.csv')\nfeature_dict.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:01.762241Z","iopub.execute_input":"2025-01-04T14:07:01.762574Z","iopub.status.idle":"2025-01-04T14:07:01.783519Z","shell.execute_reply.started":"2025-01-04T14:07:01.762540Z","shell.execute_reply":"2025-01-04T14:07:01.782526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:01.785302Z","iopub.execute_input":"2025-01-04T14:07:01.785528Z","iopub.status.idle":"2025-01-04T14:07:01.798920Z","shell.execute_reply.started":"2025-01-04T14:07:01.785509Z","shell.execute_reply":"2025-01-04T14:07:01.797849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\ndf_test = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:01.800414Z","iopub.execute_input":"2025-01-04T14:07:01.800729Z","iopub.status.idle":"2025-01-04T14:07:02.044021Z","shell.execute_reply.started":"2025-01-04T14:07:01.800693Z","shell.execute_reply":"2025-01-04T14:07:02.043003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.shape, df_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:02.044954Z","iopub.execute_input":"2025-01-04T14:07:02.045231Z","iopub.status.idle":"2025-01-04T14:07:02.050710Z","shell.execute_reply.started":"2025-01-04T14:07:02.045207Z","shell.execute_reply":"2025-01-04T14:07:02.049610Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data inspecting and Understanding","metadata":{}},{"cell_type":"code","source":"target_cols = [x for x in df_train.columns if x not in df_test.columns]\ntarget_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:02.051837Z","iopub.execute_input":"2025-01-04T14:07:02.052200Z","iopub.status.idle":"2025-01-04T14:07:02.064179Z","shell.execute_reply.started":"2025-01-04T14:07:02.052144Z","shell.execute_reply":"2025-01-04T14:07:02.063482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[['efs', 'efs_time']].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:02.066351Z","iopub.execute_input":"2025-01-04T14:07:02.066636Z","iopub.status.idle":"2025-01-04T14:07:02.086534Z","shell.execute_reply.started":"2025-01-04T14:07:02.066608Z","shell.execute_reply":"2025-01-04T14:07:02.085632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.select_dtypes(include = ['number']).corr()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:02.088017Z","iopub.execute_input":"2025-01-04T14:07:02.088260Z","iopub.status.idle":"2025-01-04T14:07:02.169445Z","shell.execute_reply.started":"2025-01-04T14:07:02.088239Z","shell.execute_reply":"2025-01-04T14:07:02.168546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import cm\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:02.170366Z","iopub.execute_input":"2025-01-04T14:07:02.170631Z","iopub.status.idle":"2025-01-04T14:07:02.174578Z","shell.execute_reply.started":"2025-01-04T14:07:02.170611Z","shell.execute_reply":"2025-01-04T14:07:02.173497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_train = df_train.isnull()\nmissing_test = df_test.isnull()\n\nfig, axes = plt.subplots(1, 2, figsize = (18, 6))\n\nsns.heatmap(missing_train, cmap='viridis', cbar=True, yticklabels=False, ax=axes[0])\naxes[0].set_title('Missing Values Heatmap - Training Dataset', fontsize=14)\naxes[0].set_xlabel('Features', fontsize=12)\naxes[0].set_ylabel('Entries', fontsize=12)\n\nsns.heatmap(missing_test, cmap='viridis', cbar=True, yticklabels=False, ax=axes[1])\naxes[1].set_title('Missing Values Heatmap - Test Dataset', fontsize=14)\naxes[1].set_xlabel('Features', fontsize=12)\naxes[1].set_ylabel('Entries', fontsize=12)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:02.175591Z","iopub.execute_input":"2025-01-04T14:07:02.176094Z","iopub.status.idle":"2025-01-04T14:07:05.169503Z","shell.execute_reply.started":"2025-01-04T14:07:02.176065Z","shell.execute_reply":"2025-01-04T14:07:05.168638Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are lots of missing value in train set","metadata":{}},{"cell_type":"code","source":"def missing_values_table(df):\n    missing_cnt = df.isnull().sum()\n    missing_percent = 100 * missing_cnt / len(df)\n    datatypes = df.dtypes\n    return pd.DataFrame({\n        'Missing Values': missing_cnt,\n        'Missing Percent': missing_percent,\n        'Data Type': datatypes\n    })\n\n\ntrain_missing_table = missing_values_table(df_train)\ntest_missing_table = missing_values_table(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:05.170309Z","iopub.execute_input":"2025-01-04T14:07:05.170593Z","iopub.status.idle":"2025-01-04T14:07:05.219528Z","shell.execute_reply.started":"2025-01-04T14:07:05.170562Z","shell.execute_reply":"2025-01-04T14:07:05.218922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Missing Values Table - Training Dataset:\\n\")\ndisplay(train_missing_table[train_missing_table['Missing Values'] > 0].sort_values(by = ['Missing Percent'], ascending=False))\nprint(\"\\n\")\n\nprint(\"Missing Values Table - Test Dataset:\\n\")\ndisplay(test_missing_table[test_missing_table['Missing Values'] > 0].sort_values(by = ['Missing Percent'], ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:05.220152Z","iopub.execute_input":"2025-01-04T14:07:05.220338Z","iopub.status.idle":"2025-01-04T14:07:05.240600Z","shell.execute_reply.started":"2025-01-04T14:07:05.220321Z","shell.execute_reply":"2025-01-04T14:07:05.239681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"high_percent_missing_features = ['tce_match', 'mrd_hct', 'cyto_score_detail', 'tce_div_match', 'tce_imm_match', 'cyto_score']\n\nfeature_dict.query('@feature_dict.variable in @high_percent_missing_features')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:05.241500Z","iopub.execute_input":"2025-01-04T14:07:05.241734Z","iopub.status.idle":"2025-01-04T14:07:05.252615Z","shell.execute_reply.started":"2025-01-04T14:07:05.241702Z","shell.execute_reply":"2025-01-04T14:07:05.251746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_missing = train_missing_table[train_missing_table['Missing Values'] > 0].sort_values(by = ['Missing Percent'], ascending=False)\ntest_missing = test_missing_table[test_missing_table['Missing Values'] > 0].sort_values(by = ['Missing Percent'], ascending=False)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\n# Bar plot for train dataset\ntrain_colors = cm.get_cmap('viridis', len(train_missing))(range(len(train_missing)))\naxes[0].barh(train_missing.index, train_missing['Missing Percent'], color=train_colors)\naxes[0].set_title('Percentage of Missing Values (Train Data)', fontsize=12)\naxes[0].set_xlabel('Percentage (%)', fontsize=10)\naxes[0].set_ylabel('Features', fontsize=10)\naxes[0].grid(axis='x', linestyle='--', alpha=0.6)\naxes[0].invert_yaxis()\n\n# Bar plot for test dataset\ntest_colors = cm.get_cmap('viridis', len(test_missing))(range(len(test_missing)))\naxes[1].barh(test_missing.index, test_missing['Missing Percent'], color=test_colors)\naxes[1].set_title('Percentage of Missing Values (Test Data)', fontsize=12)\naxes[1].set_xlabel('Percentage (%)', fontsize=10)\naxes[1].grid(axis='x', linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:05.253587Z","iopub.execute_input":"2025-01-04T14:07:05.253912Z","iopub.status.idle":"2025-01-04T14:07:06.235094Z","shell.execute_reply.started":"2025-01-04T14:07:05.253881Z","shell.execute_reply":"2025-01-04T14:07:06.234273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = df_train.copy()\ntest_data = df_test.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:06.236060Z","iopub.execute_input":"2025-01-04T14:07:06.236322Z","iopub.status.idle":"2025-01-04T14:07:06.247129Z","shell.execute_reply.started":"2025-01-04T14:07:06.236284Z","shell.execute_reply":"2025-01-04T14:07:06.246212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_columns = train_data.select_dtypes(include=['number']).columns\nfor col in numeric_columns:\n    if col in test_data.columns:\n        median_value = train_data[col].median()  # Calculate the median\n        train_data[col].fillna(median_value, inplace=True)\n        test_data[col].fillna(median_value, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:06.247917Z","iopub.execute_input":"2025-01-04T14:07:06.248122Z","iopub.status.idle":"2025-01-04T14:07:06.287915Z","shell.execute_reply.started":"2025-01-04T14:07:06.248104Z","shell.execute_reply":"2025-01-04T14:07:06.286863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"object_columns = train_data.select_dtypes(include=['object']).columns\nfor col in object_columns:\n    if col in test_data.columns:\n        train_data[col].fillna(\"<UNK>\", inplace=True)\n        test_data[col].fillna(\"<UNK>\", inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:06.288735Z","iopub.execute_input":"2025-01-04T14:07:06.288997Z","iopub.status.idle":"2025-01-04T14:07:06.367330Z","shell.execute_reply.started":"2025-01-04T14:07:06.288974Z","shell.execute_reply":"2025-01-04T14:07:06.366316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify Missing Values\n\nprint(\"Missing Values After Imputation - Training Dataset:\")\nprint(train_data.isnull().sum())\n\nprint(\"\\nMissing Values After Imputation - Test Dataset:\")\nprint(test_data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:06.368219Z","iopub.execute_input":"2025-01-04T14:07:06.368454Z","iopub.status.idle":"2025-01-04T14:07:06.417480Z","shell.execute_reply.started":"2025-01-04T14:07:06.368434Z","shell.execute_reply":"2025-01-04T14:07:06.416684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for duplicate rows in the training dataset\ntrain_duplicates = train_data.duplicated().sum() # ==============================================> New way to get number of duplicated rows\nprint(f\"\\nNumber of duplicate rows in the training dataset: {train_duplicates}\")\n\n# Check for duplicate rows in the test dataset\ntest_duplicates = test_data.duplicated().sum()\nprint(f\"Number of duplicate rows in the test dataset: {test_duplicates}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:06.421022Z","iopub.execute_input":"2025-01-04T14:07:06.421350Z","iopub.status.idle":"2025-01-04T14:07:06.496831Z","shell.execute_reply.started":"2025-01-04T14:07:06.421314Z","shell.execute_reply":"2025-01-04T14:07:06.495875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"from scipy.signal import find_peaks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:06.497950Z","iopub.execute_input":"2025-01-04T14:07:06.498218Z","iopub.status.idle":"2025-01-04T14:07:06.502157Z","shell.execute_reply.started":"2025-01-04T14:07:06.498196Z","shell.execute_reply":"2025-01-04T14:07:06.501311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom colormap using viridis\nviridis_cmap = cm.get_cmap(\"viridis\")\n\ndef visualize_premium_amount_with_peaks(data, feature='Premium Amount'):\n    plt.figure(figsize=(9, 4))\n\n    # Histogram with KDE\n    plt.subplot(1, 2, 1)\n    ax = sns.histplot(data[feature], bins=30, kde=True, color=viridis_cmap(0.5))\n    plt.title(f'Histogram of {feature} with KDE', fontsize=11)\n    plt.xlabel(feature, fontsize=10)\n    plt.ylabel('Frequency', fontsize=10)\n    plt.grid(True, linestyle='--', alpha=0.6)\n\n    # Extract KDE values to find peaks\n    kde = sns.kdeplot(data[feature], ax=ax, color=viridis_cmap(0.7)).lines[0].get_data()\n    kde_x, kde_y = kde[0], kde[1]\n    peaks, _ = find_peaks(kde_y)\n\n    # Highlight peaks\n    for peak_idx in peaks:\n        plt.plot(kde_x[peak_idx], kde_y[peak_idx], \"ro\")  # Red dots on peaks\n\n    # Box Plot\n    plt.subplot(1, 2, 2)\n    sns.boxplot(x=data[feature], color=viridis_cmap(0.5))\n    plt.title(f'Box Plot of {feature}', fontsize=11)\n    plt.xlabel(feature, fontsize=10)\n    plt.grid(True, linestyle='--', alpha=0.6)\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_premium_amount_with_peaks(train_data, feature='efs_time')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:06.503059Z","iopub.execute_input":"2025-01-04T14:07:06.503363Z","iopub.status.idle":"2025-01-04T14:07:07.468186Z","shell.execute_reply.started":"2025-01-04T14:07:06.503332Z","shell.execute_reply":"2025-01-04T14:07:07.467134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Numerical Features Distribution","metadata":{}},{"cell_type":"code","source":"columns_to_analyze = train_data.select_dtypes(include=['number']).columns.drop(target_cols)\n\nviridis_cmap = cm.get_cmap(\"viridis\")\n# Extract three colors from the colormap\nviridis_colors = [viridis_cmap(0.3), viridis_cmap(0.5), viridis_cmap(0.8)]\n\nfig, axes = plt.subplots(len(columns_to_analyze), 3, figsize=(25, len(columns_to_analyze) * 5))\n\nfor i, column in enumerate(columns_to_analyze):\n    # Histogram for train_data\n    sns.histplot(train_data[column], bins=30, kde=True, color=viridis_colors[0], ax=axes[i, 0])\n    axes[i, 0].set_title(f'Distribution of {column} (Train)', fontsize=14)\n    axes[i, 0].set_xlabel(column, fontsize=10)\n    axes[i, 0].set_ylabel('Frequency', fontsize=10)\n    axes[i, 0].grid(visible=True, linestyle='--', alpha=0.6)\n\n    # Boxplot for train_data\n    sns.boxplot(x=train_data[column], color=viridis_colors[1], ax=axes[i, 1])\n    axes[i, 1].set_title(f'Boxplot of {column} (Train)', fontsize=14)\n    axes[i, 1].set_xlabel(column, fontsize=10)\n    axes[i, 1].grid(visible=True, linestyle='--', alpha=0.6)\n\n    # Boxplot for test_data\n    sns.boxplot(x=test_data[column], color=viridis_colors[2], ax=axes[i, 2])\n    axes[i, 2].set_title(f'Boxplot of {column} (Test)', fontsize=12)\n    axes[i, 2].set_xlabel(column, fontsize=10)\n    axes[i, 2].grid(visible=True, linestyle='--', alpha=0.6)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:07.469060Z","iopub.execute_input":"2025-01-04T14:07:07.469341Z","iopub.status.idle":"2025-01-04T14:07:23.709586Z","shell.execute_reply.started":"2025-01-04T14:07:07.469320Z","shell.execute_reply":"2025-01-04T14:07:23.708443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_numeric_columns = []\nfor col in numeric_columns:\n    if(col not in target_cols and len(train_data[col].unique()) < 20):\n        cat_numeric_columns.append(col)\n\ncat_numeric_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:23.711209Z","iopub.execute_input":"2025-01-04T14:07:23.711520Z","iopub.status.idle":"2025-01-04T14:07:23.728192Z","shell.execute_reply.started":"2025-01-04T14:07:23.711496Z","shell.execute_reply":"2025-01-04T14:07:23.727323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_data = train_data.select_dtypes(include=['number'])\n\n# Compute the correlation matrix\ncorrelation_matrix = numeric_data.corr()\nplt.figure(figsize=(15, 12))\n\n# Create the heatmap\nsns.heatmap(\n    correlation_matrix,\n    annot=True,\n    fmt=\".2f\",\n    cmap='viridis',\n    cbar=True,\n    square=True,\n    mask=np.triu(np.ones_like(correlation_matrix, dtype=bool)),\n    linewidths=0.5\n)\n\nplt.title('Correlation Heatmap of Numerical Features (Excluding Target)', fontsize=12)\nplt.xticks(rotation=45, ha='right', fontsize=10)\nplt.yticks(fontsize=10)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:23.729088Z","iopub.execute_input":"2025-01-04T14:07:23.729292Z","iopub.status.idle":"2025-01-04T14:07:25.177479Z","shell.execute_reply.started":"2025-01-04T14:07:23.729273Z","shell.execute_reply":"2025-01-04T14:07:25.176330Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- High correlation between \"hla_\" features\n- Low correlation between features","metadata":{}},{"cell_type":"markdown","source":"## Categorical Features Distribution","metadata":{}},{"cell_type":"code","source":"def plot_categorical_distribution(data, column_name):\n    plt.figure(figsize=(18, 4))\n\n    # Bar plot for categorical distribution\n    plt.subplot(1, 2, 1)\n    sns.countplot(y=column_name, data=data, palette='Set2')\n    plt.title(f'Distribution of {column_name}', fontsize=12)\n    plt.xlabel('Count', fontsize=10)\n    plt.ylabel(column_name, fontsize=10)\n\n    ax = plt.gca()\n    for p in ax.patches:\n        count = int(p.get_width())\n        ax.annotate(f'{count}',\n                    (p.get_width() + 0.1, p.get_y() + p.get_height() / 2),\n                    ha='left', va='center', fontsize=10, color='black')\n\n    sns.despine(left=True, bottom=True)\n\n    # Pie chart for percentage distribution\n    plt.subplot(1, 2, 2)\n    data[column_name].value_counts().plot.pie(\n        autopct='%1.1f%%',\n        colors=sns.color_palette('Set2', data[column_name].nunique()),\n        startangle=90,\n        explode=[0.05] * data[column_name].nunique(),\n        shadow=True\n    )\n    plt.title(f'Percentage Distribution of {column_name}', fontsize=12)\n    plt.ylabel('')\n\n    plt.tight_layout()\n    plt.show()\n\ncategorical_columns = train_data.select_dtypes(include=['object'])\n\nfor column in categorical_columns:\n    plot_categorical_distribution(train_data, column)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:25.178453Z","iopub.execute_input":"2025-01-04T14:07:25.178694Z","iopub.status.idle":"2025-01-04T14:07:40.261510Z","shell.execute_reply.started":"2025-01-04T14:07:25.178673Z","shell.execute_reply":"2025-01-04T14:07:40.260538Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Most of features are dominant with 'No' value => Need oversampling with low frequency values","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:07:40.262475Z","iopub.execute_input":"2025-01-04T14:07:40.262740Z","iopub.status.idle":"2025-01-04T14:07:40.330939Z","shell.execute_reply.started":"2025-01-04T14:07:40.262717Z","shell.execute_reply":"2025-01-04T14:07:40.329991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = df_train.copy()\ntest_data = df_test.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:18:46.344717Z","iopub.execute_input":"2025-01-04T14:18:46.345032Z","iopub.status.idle":"2025-01-04T14:18:46.362288Z","shell.execute_reply.started":"2025-01-04T14:18:46.345008Z","shell.execute_reply":"2025-01-04T14:18:46.361201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.set_index('ID')\ntest_data.set_index('ID')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:18:47.333599Z","iopub.execute_input":"2025-01-04T14:18:47.333899Z","iopub.status.idle":"2025-01-04T14:18:47.367820Z","shell.execute_reply.started":"2025-01-04T14:18:47.333876Z","shell.execute_reply":"2025-01-04T14:18:47.367054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_columns = train_data.select_dtypes(include=['number']).columns\nfor col in numeric_columns:\n    if col in test_data.columns:\n        median_value = train_data[col].median()  # Calculate the median\n        train_data[col].fillna(median_value, inplace=True)\n        test_data[col].fillna(median_value, inplace=True)\n\nobject_columns = train_data.select_dtypes(include=['object']).columns\nfor col in object_columns:\n    if col in test_data.columns:\n        train_data[col].fillna(\"<UNK>\", inplace=True)\n        test_data[col].fillna(\"<UNK>\", inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:18:50.597955Z","iopub.execute_input":"2025-01-04T14:18:50.598254Z","iopub.status.idle":"2025-01-04T14:18:50.703397Z","shell.execute_reply.started":"2025-01-04T14:18:50.598232Z","shell.execute_reply":"2025-01-04T14:18:50.702710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_columns = list(train_data.select_dtypes(include=['object']).columns)\n\n# train_data = pd.get_dummies(train_data, columns=cat_columns, drop_first=True)\n# test_data = pd.get_dummies(test_data, columns=cat_columns, drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:19:14.594156Z","iopub.execute_input":"2025-01-04T14:19:14.594482Z","iopub.status.idle":"2025-01-04T14:19:14.604924Z","shell.execute_reply.started":"2025-01-04T14:19:14.594455Z","shell.execute_reply":"2025-01-04T14:19:14.604125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_columns = train_data.drop(target_cols, axis = 1).select_dtypes(include=['float64', 'int64']).columns\n\nscaler = StandardScaler()\ntrain_data[numerical_columns] = scaler.fit_transform(train_data[numerical_columns])\ntest_data[numerical_columns] = scaler.transform(test_data[numerical_columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:18:53.618341Z","iopub.execute_input":"2025-01-04T14:18:53.618634Z","iopub.status.idle":"2025-01-04T14:18:53.656762Z","shell.execute_reply.started":"2025-01-04T14:18:53.618613Z","shell.execute_reply":"2025-01-04T14:18:53.655838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"from pathlib import Path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:08:39.732358Z","iopub.execute_input":"2025-01-04T14:08:39.732756Z","iopub.status.idle":"2025-01-04T14:08:39.736722Z","shell.execute_reply.started":"2025-01-04T14:08:39.732721Z","shell.execute_reply":"2025-01-04T14:08:39.735844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    train_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n    test_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')\n    subm_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv')\n    colorscale = 'Sunset'\n    color = '#2EEFCA'\n    batch_size = 32768\n    early_stop = 300\n    penalizer = 0.01\n    n_splits = 5\n\n    ctb_params = {\n        'loss_function': 'RMSE',\n        'learning_rate': 0.03,\n        'task_type': 'GPU',\n        'num_trees': 6000,\n        'bootstrap_type': 'MVS',\n        'subsample': 0.8,\n        'reg_lambda': 8.0,\n        'depth': 8,\n        'random_state': 86,\n    }\n\n    lgb_params = {\n        'objective': 'regression',\n        'min_child_samples': 20,\n        'num_iterations': 6000,\n        'learning_rate': 0.01,\n        'extra_trees': True,\n        'reg_lambda': 3.0,\n        'reg_alpha': 0.1,\n        'num_leaves': 64,\n        'metric': 'rmse',\n        'max_depth': 10,\n        'device': 'gpu',\n        'max_bin': 255,\n        'verbose': -1,\n        'seed': 86\n    }\n\n    cox1_params = {\n        'grow_policy': 'Depthwise',\n        'min_child_samples': 8,\n        'loss_function': 'Cox',\n        'learning_rate': 0.03,\n        'task_type': 'CPU',\n        'num_trees': 6000,\n        'bootstrap_type': 'MVS',\n        'subsample': 0.6,  \n        'reg_lambda': 8.0,\n        'depth': 8,\n        'random_state': 86,\n    }\n\n    cox2_params = {\n        'grow_policy': 'Lossguide',\n        'loss_function': 'Cox',\n        'learning_rate': 0.03,\n        'task_type': 'CPU',\n        'num_trees': 6500,\n        'bootstrap_type': 'MVS',\n        'subsample': 0.6,  \n        'reg_lambda': 8.0,\n        'num_leaves': 32,\n        'depth': 8,\n        'random_state': 86,\n    }\n\n    cox3_params = {\n        'grow_policy': 'Depthwise',\n        'min_child_samples': 16,\n        'loss_function': 'Cox',\n        'learning_rate': 0.02,\n        'task_type': 'CPU',\n        'num_trees': 7000,\n        'bootstrap_type': 'MVS',\n        'subsample': 0.5,  \n        'reg_lambda': 6.0,\n        'depth': 10,\n        'random_state': 86,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:24:35.887353Z","iopub.execute_input":"2025-01-04T14:24:35.887668Z","iopub.status.idle":"2025-01-04T14:24:35.894505Z","shell.execute_reply.started":"2025-01-04T14:24:35.887646Z","shell.execute_reply":"2025-01-04T14:24:35.893611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model building","metadata":{}},{"cell_type":"code","source":"!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T02:54:36.161421Z","iopub.execute_input":"2025-01-05T02:54:36.161719Z","iopub.status.idle":"2025-01-05T02:54:54.475144Z","shell.execute_reply.started":"2025-01-05T02:54:36.161697Z","shell.execute_reply":"2025-01-05T02:54:54.474244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold\nfrom lifelines import CoxPHFitter, KaplanMeierFitter, NelsonAalenFitter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T15:09:27.310917Z","iopub.execute_input":"2025-01-04T15:09:27.311233Z","iopub.status.idle":"2025-01-04T15:09:27.315874Z","shell.execute_reply.started":"2025-01-04T15:09:27.311210Z","shell.execute_reply":"2025-01-04T15:09:27.314898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lifelines.utils import concordance_index\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n    \n    event_label = 'efs'\n    interval_label = 'efs_time'\n    prediction_label = 'prediction'\n    \n    # Merging solution and submission dfs on ID\n    merged_df = pd.concat([solution, submission], axis=1)\n    merged_df.reset_index(inplace=True)\n    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n    metric_list = []\n    for race in merged_df_race_dict.keys():\n        # Retrieving values from y_test based on index\n        indices = sorted(merged_df_race_dict[race])\n        merged_df_race = merged_df.iloc[indices]\n        # Calculate the concordance index\n        c_index_race = concordance_index(\n                        merged_df_race[interval_label],\n                        -merged_df_race[prediction_label],\n                        merged_df_race[event_label])\n        metric_list.append(c_index_race)\n    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T15:17:51.448769Z","iopub.execute_input":"2025-01-04T15:17:51.449163Z","iopub.status.idle":"2025-01-04T15:17:51.455211Z","shell.execute_reply.started":"2025-01-04T15:17:51.449136Z","shell.execute_reply":"2025-01-04T15:17:51.454325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MD:\n    def __init__(self, early_stop, penalizer, n_splits, color):\n        self.early_stop = early_stop\n        self.penalizer = penalizer\n        self.n_splits = n_splits\n        self.color = color\n\n    def create_target1(self, data, cat_cols):\n        cph_data = pd.get_dummies(data, columns=cat_cols, drop_first=True)\n        cph = CoxPHFitter(penalizer=self.penalizer)\n        cph.fit(cph_data, duration_col='efs_time', event_col='efs')\n        data['target1'] = cph.predict_partial_hazard(cph_data)\n        return data\n\n    def create_target2(self, data):\n        kmf = KaplanMeierFitter()\n        kmf.fit(durations=data['efs_time'], event_observed=data['efs'])\n        data['target2'] = kmf.survival_function_at_times(data['efs_time']).values\n        return data\n\n    def create_target3(self, data):\n        naf = NelsonAalenFitter()\n        naf.fit(durations=data['efs_time'], event_observed=data['efs'])\n        data['target3'] = naf.cumulative_hazard_at_times(data['efs_time']).values\n        data['target3'] = data['target3'] * -1\n        return data\n\n    def create_target4(self, data):\n        data['target4'] = data.efs_time.copy()\n        data.loc[data.efs == 0, 'target4'] *= -1\n        return data\n\n    def train_model(self, data, cat_cols, params, target, title):\n        for col in cat_cols:\n            data[col] = data[col].astype('category')\n            \n        X = data.drop(['ID', 'efs', 'efs_time', 'target1', 'target2', 'target3', 'target4'], axis=1)\n        y = data[target]\n        \n        models, fold_scores = [], []\n        \n        cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=86)\n        \n        oof_preds = np.zeros(len(X))\n        \n        for fold, (train_index, valid_index) in enumerate(cv.split(X)):\n            X_train = X.iloc[train_index]\n            X_valid = X.iloc[valid_index]\n            y_train = y.iloc[train_index]\n            y_valid = y.iloc[valid_index]\n            \n            if title.startswith('LightGBM'):\n                model = lgb.LGBMRegressor(**params)\n                model.fit(\n                    X_train, y_train,\n                    eval_set=[(X_valid, y_valid)],\n                    eval_metric='rmse',\n                    callbacks=[\n                        lgb.early_stopping(self.early_stop, verbose=0),\n                        lgb.log_evaluation(0)\n                    ]\n                )\n                \n            elif title.startswith('CatBoost'):\n                model = CatBoostRegressor(**params, verbose=0, cat_features=cat_cols)\n                model.fit(\n                    X_train, y_train,\n                    eval_set=(X_valid, y_valid),\n                    early_stopping_rounds=self.early_stop,\n                    verbose=0\n                )\n                \n            models.append(model)\n            oof_preds[valid_index] = model.predict(X_valid)\n            \n            y_true_fold = data.iloc[valid_index][['ID', 'efs', 'efs_time', 'race_group']].copy()\n            y_pred_fold = data.iloc[valid_index][['ID']].copy()\n            y_pred_fold['prediction'] = oof_preds[valid_index]\n            \n            fold_score = score(y_true_fold, y_pred_fold, 'ID')\n            fold_scores.append(fold_score)\n        \n        y_true = data[['ID', 'efs', 'efs_time', 'race_group']].copy()\n        y_pred = data[['ID']].copy()\n        y_pred['prediction'] = oof_preds\n        \n        c_index_score = score(y_true.copy(), y_pred.copy(), 'ID')\n        if target == 'target1':\n            t = 'Cox Target'\n        elif target == 'target2':\n            t = 'Kaplan-Meier Target'\n        elif target == 'target3':\n            t = 'Nelson-Aalen Target'\n        else:\n            t = 'Cox Loss'\n        print(f'\\nOverall C-Index for {title} {t}: {c_index_score:.3f}\\n')\n        \n        return models, oof_preds\n\n    def infer_model(self, data, cat_cols, models):\n        data = data.drop(['ID'], axis=1)\n        for col in cat_cols:\n            data[col] = data[col].astype('category')\n        return np.mean([model.predict(data) for model in models], axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T15:10:05.795491Z","iopub.execute_input":"2025-01-04T15:10:05.795929Z","iopub.status.idle":"2025-01-04T15:10:05.809648Z","shell.execute_reply.started":"2025-01-04T15:10:05.795865Z","shell.execute_reply":"2025-01-04T15:10:05.808580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"md = MD(CFG.early_stop, CFG.penalizer, CFG.n_splits, CFG.color)\n\ntrain_data = md.create_target1(train_data, cat_columns)\ntrain_data = md.create_target2(train_data)\ntrain_data = md.create_target3(train_data)\ntrain_data = md.create_target4(train_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T15:10:10.995945Z","iopub.execute_input":"2025-01-04T15:10:10.996271Z","iopub.status.idle":"2025-01-04T15:11:21.550499Z","shell.execute_reply.started":"2025-01-04T15:10:10.996245Z","shell.execute_reply":"2025-01-04T15:11:21.549725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training CatBoost models...\")\nctb1_models, _ = md.train_model(train_data, cat_columns, CFG.ctb_params, target='target1', title='CatBoost1')\nctb2_models, _ = md.train_model(train_data, cat_columns, CFG.ctb_params, target='target2', title='CatBoost2')\nctb3_models, _ = md.train_model(train_data, cat_columns, CFG.ctb_params, target='target3', title='CatBoost3')\n\nprint(\"\\nTraining LightGBM models...\")\nlgb1_models, _ = md.train_model(train_data, cat_columns, CFG.lgb_params, target='target1', title='LightGBM1')\nlgb2_models, _ = md.train_model(train_data, cat_columns, CFG.lgb_params, target='target2', title='LightGBM2')\nlgb3_models, _ = md.train_model(train_data, cat_columns, CFG.lgb_params, target='target3', title='LightGBM3')\n\nprint(\"\\nTraining Cox models...\")\ncox1_models, _ = md.train_model(train_data, cat_columns, CFG.cox1_params, target='target4', title='CatBoost')\ncox2_models, _ = md.train_model(train_data, cat_columns, CFG.cox2_params, target='target4', title='CatBoost')\ncox3_models, _ = md.train_model(train_data, cat_columns, CFG.cox3_params, target='target4', title='CatBoost')\n\nctb1_preds = md.infer_model(test_data, cat_columns, ctb1_models)\nctb2_preds = md.infer_model(test_data, cat_columns, ctb2_models)\nctb3_preds = md.infer_model(test_data, cat_columns, ctb3_models)\n\nlgb1_preds = md.infer_model(test_data, cat_columns, lgb1_models)\nlgb2_preds = md.infer_model(test_data, cat_columns, lgb2_models)\nlgb3_preds = md.infer_model(test_data, cat_columns, lgb3_models)\n\ncox1_preds = md.infer_model(test_data, cat_columns, cox1_models)\ncox2_preds = md.infer_model(test_data, cat_columns, cox2_models)\ncox3_preds = md.infer_model(test_data, cat_columns, cox3_models)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T15:17:56.083477Z","iopub.execute_input":"2025-01-04T15:17:56.083808Z","iopub.status.idle":"2025-01-04T16:05:52.187071Z","shell.execute_reply.started":"2025-01-04T15:17:56.083756Z","shell.execute_reply":"2025-01-04T16:05:52.185822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create ensemble models","metadata":{}},{"cell_type":"code","source":"from scipy.stats import rankdata ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:05:40.912698Z","iopub.status.idle":"2025-01-04T14:05:40.913080Z","shell.execute_reply":"2025-01-04T14:05:40.912921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = [\n    ctb1_preds, ctb2_preds, ctb3_preds,\n    lgb1_preds, lgb2_preds, lgb3_preds,\n    cox1_preds, cox2_preds, cox3_preds,\n]\n\nweights = [\n    0.55, 3.0, 3.0,  # CatBoost weights\n    0.55, 2.0, 2.0,  # LightGBM weights\n    2.5, 2.5, 2.5,   # Cox weights \n]\n\nranked_preds = np.array([rankdata(p) for p in preds])\nensemble_preds = np.sum([w * p for w, p in zip(weights, ranked_preds)], axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:05:40.913953Z","iopub.status.idle":"2025-01-04T14:05:40.914269Z","shell.execute_reply":"2025-01-04T14:05:40.914158Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Create submission\nsubm_data = pd.read_csv(CFG.subm_path)\nsubm_data['prediction'] = ensemble_preds\nsubm_data.to_csv('submission.csv', index=False)\ndisplay(subm_data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:05:40.914852Z","iopub.status.idle":"2025-01-04T14:05:40.915134Z","shell.execute_reply":"2025-01-04T14:05:40.915027Z"}},"outputs":[],"execution_count":null}]}